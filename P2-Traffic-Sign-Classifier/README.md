## Building a Traffic Sign Classifier

![traffic signs](img/Model_archi.png)

Overview
---
In this project, deep learning techniques and convolutional neural networks were applied to classify traffic signs. The traffic sign images are from [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset). After training, the images of the traffic signs from the Internet were incorporated to test the performance on the model .

Files
---
The structure and useage of the files in this repository are as follows:

1. `Main_pipeline.ipynb` and `Main_pipeline.html`
  - This part mainly contains the data exploration, visualization, preprocessing, model architecture and evaluation on test images.

2. `model_ec2.ipynb`
  - Most part of this file are the same the previous one. The differences are the code and training procedure. This file was run on AWS EC2 with GPU, so more parameter tuning were tried on the files. Also, some code change on Keras was performed to solve the compatibility issue. Some details could be found in the `Readme.md` of another depository [test_on_AWS_EC2](https://github.com/YouYueHuang/test_on_AWS_EC2)

3. `model_reshuffled_data.ipynb`
  - Most part of this file are the same the previous one. The only difference is the data. The training, test and validation sets are under mixing, shuffling and partitioning to recreate new datasets.

4. `download_file.py`
  - This file contains the functions to download the data because the original data size is over 100 MB and it could not be uploaded to Github.

5. `test_images`
  - It contains 10 images from the Internet for testing, and the file name is its class. Each image are resized to 32*32 already.
  - In web_crawler, there are 5 directories and test images with the file name of its class. They were crawled with [icrawler](https://pypi.python.org/pypi/icrawler), and the image size are not a fixed number.

6. `model`
  - It contains the weight of trained model. All are in the directory of `EC2_model`

7. `img`
  - It stores the images during analysis

8. `test`
  - It contains some functions for preprocessing (grayscale, contrast-limited adaptive histogram equalization, histogram of oriented gradients, data augmentation, data shuffeling and partitioning, stratified sampling, Xavier weight initialization), visualization(tensorboard, graphviz), CNN model framework(inception, devolution net). 

9. `ref`
  - It stores the papers of related research work.

10. `logs`
  - It stores the summary of model training log in previous models, and it is mainly for visualization with TensorBoard. It is abandoned for this moment.

[//]: # (Image References)

[image10]: ./img/traffic_signs.png "traffic_signs"
[image2]: ./img/dataset_histogram.png "The Histogram of training set distribution"
[image9]: ./img/distribution_of_class_frequency.png "Training Dataset probability distribution"
[image1]: ./img/dataset_samples.png "Dataset samples visualization"
[image3]: ./img/confusion_matrix.png "Confustion matrix of validation dataset"
[image11]: ./img/training_strategy.png "training strategy"
[image14]: ./img/preprocessed_image.png "preprocessed image"

[image4]: ./img/top5_prediction_1.png "top5 prediction of test Samples 1"
[image5]: ./img/top5_prediction_2.png "top5 prediction of test Samples 2"
[image6]: ./img/data_augmentation_histogram.png "the data number of each class after data augmentation"
[image7]: ./img/error_analysis_1.png "error analysis 1"
[image8]: ./img/error_analysis_2.png "error analysis 2"
[image12]: ./img/model_accuracy.png "model_accuracy"
[image13]: ./img/model_loss.png "model loss"
[image15]: ./img/class05.png "class05"
[image16]: ./img/class19.png "class19"

Data exploration
---
1. Dataset Summary

  * The training data set consists of 43 classes of colored traffic sign images 32x32 in size.
  * The number of training set: 34799.
  * The number of validation set: 4410.
  * The number of test set: 12630.

2. Exploratory Visualization

The following figure shows sample image of each class.
![alt text][image10]

Normalized frequencies of each class in the training, validation and test set are shown below. It shows that the original datasets were sampled evenly for each class, so the these three sets follows the same distribution. 
![alt text][image9]

Next, We plotted the histogram of Training data to give intuition on the frequency distrpution.
![alt text][image2]

Data Pipeline
---
1. Preprocessing

  - [Data augmentation](https://github.com/vxy10/ImageAugmentation): Due to limited data and the class imbalance, additional data was generated by affine transformation. After data augmentation, the size of of each class in training set is at least 600. The size of training set becomes 41469. The transformations include: 
    (1) rotation with random number generated between +/- 15 degress 
    (2) translation by +/- 10 pixels along vertical and horizontal direction
    (3) shearing

The example of augmented data is as follows:

<table>
  <tr>
    <td>Origin image</td>
    <td>Affine Transformed images</td>
  </tr> 
  <tr>
    <td><img src='./img/sample_traffic_sign.jpg' style='width: 500px;'></td>
    <td><img src='./img/dataAugment.png' style='width: 500px;'></td>
  </tr>
</table>
  
  - Image sharening: Gaussian blur was applied to increase the contrast of images.

The example of image sharening (Speed limit (30km/h))
![alt text][image14]

  - Image normalization: The RGB value of a image is divided by 255, and the range is between 0~1.
  - Dataset shuffling: It is applied to increase the robustness.

2. Model architecture

  - Components: There are three types of component in this architecture (1)conv-L2-batchnorm-relu (2)maxpool-dropout (3) fully connection-relu-dropout. Pooling reduces signal and makes the model more robust against spatial invariance. The exact amount of maxpooling will make the model work fine and reduce the parameter. Fully connected layer are applied at the end to classify the images to their classes. 

  - Regularization: The combination of L2 and dropout will act as a regularizer, preventing overfitting and keeping the weights small so that the model is able to generalize pretty well.

  - Batch Normalizaion: It is applied for preventing the interaction of each layer and the saturation of the filters after activation.

  - Parameters:
    * Learning rate :0.0001 ~ 0.00001
    * Batch size: 128
    * Epoch: 60 (30+30)  
    * Keep probability: 0.1 ~ 0.3 
    * Weight decay: 1e-4 ~ 5e-5

The training model is built using keras containing layers as described below:

```python 

    # 1: convolutional layer: kernel size 3x3 (input), L2 regularization with weight_decay 1e-4
    model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    
    # 2: maxpool layer: kernel size 2x2
    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))
    model.add(Dropout(0.2))

    # 3: convolutional layer: kernel size 3x3, L2 regularization with weight_decay 1e-4
    model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))
    model.add(BatchNormalization())
    model.add(Activation('relu'))

    # 4: maxpool layer: kernel size 2x2
    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))
    model.add(Dropout(0.2))
    
    # 5: convolutional layer: kernel size 3x3, L2 regularization with weight_decay 1e-4
    model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    
    # 6: maxpool layer: kernel size 2x2
    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))
    model.add(Dropout(0.3))
    
    model.add(Flatten())
    
    # 7: fully-connected layter: 256 neurons
    model.add(Dense(256))
    model.add(Activation('relu'))
    model.add(Dropout(0.3))
    
    # 8: fully-connected layter: 128 neurons
    model.add(Dense(128))
    model.add(Activation('relu'))
    model.add(Dropout(0.1))
    
    # 9: fully-connected layter: 43 neurons with softmax function (output)
    model.add(Dense(43))
    model.add(Activation('softmax'))

    # total parameters: 427,755
    # model size: 1,718 KB
```

3. Early stopping
  - It is applied for regularization to avoid overfitting. The accuracy of test set will increase and then decrease due to the overfitting. Therefore, if the accuracy achieve 93%, the training will be stopped.

The workflow of model training strategy
![alt text][image11]

4. Evaluation
  - There is no golden rule for a good validation frequency. Validation error was computed after each epoch.

Result
---

1. accuracy and loss

  - The model can achieve 99% accuracy on training set without regularization techniques(e.g, dropout, L2), but the accuracy on test set and validation set are about 93% and 93.5% respectively. The loss on training, test and validation set are 0.360, 0.401 and 0.057. 

The following figure shows accuracy and loss on three datasets(training, test, validation) after the measurements approach stable 

<table>
  <tr>
    <td>Accuracy of training and test set</td>
    <td>Loss of training and test set</td>
  </tr> 
  <tr>
    <td><img src='./img/model_accuracy.png' style='width: 500px;'></td>
    <td><img src='./img/model_loss.png' style='width: 500px;'></td>
  </tr>
</table>

2. confusion matrix and error analysis

The following figure shows confusion matrix and the performance in each class.
![alt text][image3]

  - There are 5 parts with relatively low performace:
    (1) 58 images of class 4 and 27 images of class 8 were misclassied as class 19
    (2) 26 images of class 7 were misclassied as class 5
    (3) 16 images of class 31 were misclassied as class 23
    (4) 19 images of class 16 were misclassied as class 41

  - For simplicity, only the part (1) will be discussed. Let's take two misclassified example from class 8 and class 4. The samples show that the brighness of the images are quite low.

The following figure shows (from left to right) the misclassfied example (class 8) of the sign "Speed limit (120km/h)", its (class 8) result after sharpening, its (class 8) result after CLAHE, the example of predicted class "Dangerous curve to the left" and its (class 19) result after CLAHE
![alt text][image7]: ./img/error_analysis_1.png "error analysis 1"

The following figure shows (from left to right) the misclassfied example (class 4) of the sign "Speed limit (70km/h)", its (class 4) result after sharpening, its (class 4) result after CLAHE, the example of predicted class "Dangerous curve to the left" and its (class 19) result after CLAHE
![alt text][image8]: ./img/error_analysis_2.png "error analysis 2"

  - For generalization, let's take a look for more sample from class 4 and class 19, and it is not hard to imagine why the misclassified images were recognized as the sign "Dangerous curve to the left". Most of the samples from class 19 are nearly dark, and the misclassified image(class 4) does not like most of its samples at all.

The following figure shows more samples of the sign "Speed limit (70km/h)" (class 4)
![alt text][image15]: ./img/class05.png "class05"

The following figure shows more samples of the sign "Dangerous curve to the left" (class 19)
![alt text][image16]: ./img/class19.png "class19"

3. Top 5 prediction on new images

Due to the fixed size of input, the images need to be resized if the size is not 32*32. The test accuracy are 1 for images with size of 32*32 and 0 for those with unfixed size. From the pictures, it is clear that the signs become unrecognizable after resizing. 

The following figure shows top 5 prediction on 10 new images with size of 32*32
![alt text][image4]: ./img/top5_prediction_1.png "top5 prediction of test Samples 1"

The following figure shows top 5 prediction on 5 new images with random size
![alt text][image5]: ./img/top5_prediction_2.png "top5 prediction of test Samples 2"

Conclusion
---

* Model architecture and performance 
  - The high accuracy on the training set but low accuracy on the validation and test set implies overfitting. Without the dropout, the accuracy on training set can be as high as over 99%, but the performance are below 93% for other sets. The change of L2 just made the model more underfitting on both training set and validation set, so the fine-funning works are done on the adjustment of keeping probability. The policy of tuning was to reduce the difference of loss on training set and validation set while achieving 93% accuracy.

The accuracY of training set is about 4% higher than that of test set, and the loss is 0.25 less. Over 99% indicates there is space for improvent on training set, but the model could be generalized for test set by sacrifice the accuracy of training set 
![alt text][image12]: ./img/model_accuracy.png "model_accuracy"
![alt text][image13]: ./img/model_loss.png "model loss"

  - Without maxpool layer, the space use could be as high as 1 GB based on tensorflow. In contrast, keras takes only ~1 MB to store weight.

* Test on images from the Internet

  - When image is well processed and selected, the accuracy on test images could almost achieve accuracy of 100%, but the signs could not be recognized if we used the test images with unfixed size. The image size and ratio from the Internet are quite diverse. Without the aid of object localization, there might be many noises on the image (e.g, car, electric pole, building, etc.) After resizing, the images are seriously distorted, which makes the key features harder to be detected in the model.

* The issues in preprocessing

  - Due to the class imbalance, a data augmentation algorithm was applied to compensate the lack of traffic signs of some categories. The algorithm calculates the number of a class and decided if the image of that class needs to be generated. If the number is less than the threshold, the algorithm will generate 10 images and append them to the origin image. According to the result of error analysis, there was a trend that the misclassified images occured in series. After checking the misclassified images, it turns out that the sharpening could not enhance the contrast of the dark images well (some are even worse) so that the number of wrongly processed images were generated. If preprocessed images owns some features similar to other classes, that might confuse the model and the performance would be degenerated.



### Refrences

1. [Example of Tensorboard](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/4_Utils/tensorboard_basic.py)
2. [Example of saving and restoring model in Tensorflow](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/4_Utils/save_restore_model.py)
3. [The code of Data augmentation](https://github.com/aleju/imgaug) from aleje.
4. [Understanding data augmentation for classification:when to warp?](https://arxiv.org/pdf/1609.08764.pdf)

The following figure shows some sample images of each class to visualize the general view.
![alt text][image1]